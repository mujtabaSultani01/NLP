{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb0716b",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "**Bag of words (BoW)** is a natural language processing technique used for text analysis and feature extraction. It involves representing a piece of text as a collection or \"bag\" of its individual words, disregarding grammar and word order. The BoW model counts the frequency of each word in the text and creates a numerical vector representing the occurrence of each word in the document. This vector can then be used as input for machine learning algorithms to classify or analyze the text data. BoW is commonly used in sentiment analysis, spam detection, and topic modeling.\n",
    "\n",
    "Bag of words is a technique used in natural language processing to represent text data as a collection of words or tokens, without considering their order or context. It is called a \"bag\" because it treats the text as a unordered set of words, similar to how a bag contains a collection of objects without any specific order.\n",
    "\n",
    "Bag of words is used because it simplifies the text data and makes it easier to analyze and process. By breaking down the text into individual words, it allows for simple counting and statistical analysis of the frequency of each word. This can be used for various tasks such as sentiment analysis, topic modeling, and text classification.\n",
    "\n",
    "Additionally, bag of words is language independent, meaning it can be applied to any language without the need for language-specific tools or resources. It is also computationally efficient, making it suitable for processing large amounts of text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c10f3",
   "metadata": {},
   "source": [
    "* Normally the process is such, first we create a vocabulary of all unique words from n articles. In the second steps we count each word appearance in each article. The appearance of words for each article is represented in a vectors, this vectors are also called **Count Vectorizer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5b80d",
   "metadata": {},
   "source": [
    "<img src = \"img.jpg\" width = \"800px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c974e99",
   "metadata": {},
   "source": [
    "* So here tackle with a classical **Spam** problem. We'll take an email body then we'll convert it into a numbers using **Bag Of Words (BoW** model and then we'll apply **Naive Bayes** classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4dee4",
   "metadata": {},
   "source": [
    "* So to classify emails, **first** we need to create a **vocabulay**, vocabulary is the unique count of words in all your emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0537680",
   "metadata": {},
   "source": [
    "<img src = \"img1.jpg\" width = \"800px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44795d",
   "metadata": {},
   "source": [
    "* **Next we'll build a **Bag Of Words (BoW)** or **Count Vectorizer** where we take an email and we count the word appearance as vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ce0a3",
   "metadata": {},
   "source": [
    "<img src = \"img2.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978f02f",
   "metadata": {},
   "source": [
    "* So there are certain limitation of **BoW** model which is listed bellow:\n",
    "\n",
    "    **1.** Your vocabulary will be locked and we have **Sparse Representation.** Sparse Representation means, it may consume to much memory & compute resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e41f16",
   "metadata": {},
   "source": [
    "<img src = \"img3.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d7f0c",
   "metadata": {},
   "source": [
    "   * **2.** It doesn't capture the meanings of words accurately. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4b0f03",
   "metadata": {},
   "source": [
    "<img src = \"img4.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40791bad",
   "metadata": {},
   "source": [
    "* **So let's got spam and non spam (ham) email classification problem using BoW for text representation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b42ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d96ba05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why you Dint come with us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>ham</td>\n",
       "      <td>You have registered Sinco as Payee. Log in at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dont talk to him ever ok its my word.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>ham</td>\n",
       "      <td>See you there!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>spam</td>\n",
       "      <td>YOU ARE CHOSEN TO RECEIVE A £350 AWARD! Pls ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "265       ham                         Why you Dint come with us.\n",
       "1400      ham  You have registered Sinco as Payee. Log in at ...\n",
       "920       ham              Dont talk to him ever ok its my word.\n",
       "2873      ham                                     See you there!\n",
       "5232     spam  YOU ARE CHOSEN TO RECEIVE A £350 AWARD! Pls ca..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have an email dataset which has more than 500 spam and ham emails, and we want to use it for email classification prob.\n",
    "# Let's load the dataset:\n",
    "df = pd.read_csv(\"spam.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ad6d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the first thing we want to do is, knowing how many spam and non spam emails are there in the dataset:\n",
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc0520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we cleaerly see the imbalance in the dataset, but for now we skip this issue and we go ahead to build a ML model.\n",
    "# Since the spam and ham are text in the Category column, so we create a new column where for spam we'll have 1 and for non\n",
    "# spam we'll have 0.\n",
    "df['spam'] = df['Category'].apply(lambda x: 1 if x =='spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43799b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will have three columns:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3874d95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  spam\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1      ham                      Ok lar... Joking wif u oni...     0\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3      ham  U dun say so early hor... U c already then say...     0\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the columns and there values:\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ab4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we import train_test_split method from 'Sklearn' to split the dataset into train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.Message, df.spam, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6066013a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we check the number of train samples:\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c650929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the number of test samples:\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd30304b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know about the datatype of samples, we can do it using type function.\n",
    "type(X_train) # This will output that the datatype is pandas 'series'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e62ed069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445     HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYARO...\n",
       "2905    HI DARLIN I HOPE YOU HAD A NICE NIGHT I WISH I...\n",
       "1266    Im in inperialmusic listening2the weirdest tra...\n",
       "3498    Oh, the grand is having a bit of a party but i...\n",
       "2911       How do you guys go to see movies on your side.\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see first 5 samples from train samples:\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7404ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540     0\n",
       "2104    0\n",
       "1874    1\n",
       "1829    0\n",
       "20      0\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see 5 samples of test dataset:\n",
    "y_test[7:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead3f9e",
   "metadata": {},
   "source": [
    "* The reason why we use capital 'X' for X_train and small 'y' for y_train is, we may have multiple dependent variables and will be multiple columns and usually y_train is just one column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a3fdd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4457x7759 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 59567 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So in order to build BoW model for numeric representation, we import count vectorizer from sklearn.\n",
    "# So count vectorizer is a class and we want to create an instatnce from the class.\n",
    "# CountVectorizer has a method called 'fit_transform' which generate the BoW model for X_train.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer() # instance of the class.\n",
    "\n",
    "X_train_cv = v.fit_transform(X_train.values)   # So we do X_train.values, by values means to convert it into numpy array\n",
    "X_train_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00529b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the type of 'X_train.values', it will be numpy array.\n",
    "type(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50eb9e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we want to see 'X_train_cv', we have to convert it into an numpy array.\n",
    "X_train_cv.toarray()[:4]   # So we know this is a sparse representation, it's a big array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eab24488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 7759)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the shape:\n",
    "X_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "695b7089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['copy', 'cornwall', 'corrct', 'correct', 'correctly', 'corrupt',\n",
       "       'corvettes', 'cos', 'cosign', 'cost', 'costa', 'costing', 'costs',\n",
       "       'costume', 'costumes', 'cougar', 'coughing', 'could', 'coulda',\n",
       "       'couldn', 'count', 'countin', 'countinlots', 'country', 'counts',\n",
       "       'coupla', 'couple', 'courage', 'course', 'court', 'courtroom',\n",
       "       'cousin', 'cover', 'covers', 'coz', 'cozy', 'cps', 'cr01327bt',\n",
       "       'cr9', 'crab', 'crack', 'cramps', 'crap', 'crash', 'crashing',\n",
       "       'crave', 'craving', 'craziest', 'crazy', 'crazyin'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we see we have 7759 unique words in our vocabulary.\n",
    "# If we use 'v' which stored CountVectorizer, it will give us all the words.\n",
    "v.get_feature_names_out()[2000:2050]    # Will show 50 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cad4674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7759"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary size:\n",
    "# v.get_feature_names_out().shape\n",
    "len(v.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c5817d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names',\n",
       " 'get_feature_names_out',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'preprocessor',\n",
       " 'set_params',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know about all the methods which is supported by 'v' variable.\n",
    "dir(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4441ded1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now for example 'vocabulary_' will give us all the vocabulary:\n",
    "# v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "381438e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we have 4457 emails in the X_train and each email has lenght of 7675.\n",
    "# So look at to the first email\n",
    "X_train_np = X_train_cv.toarray()\n",
    "X_train_np[:2] # Will show two vectors for the first two emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c6c2dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2381, 2964, 3204, 3432, 3533, 3536, 3818, 3843, 4240, 4585, 4587,\n",
       "        5931, 5937, 7427, 7477, 7669], dtype=int64),)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As majority of values are zeroes in the vectors, so we don't see the 1s values here. To see the 1s, we point to the index\n",
    "# of 1s values.\n",
    "np.where(X_train_np[0]!=0)  # Will show the indexes where have values 1. Not exactly 1s, it may be 2, 3 ,10 ... but not 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a97a5d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to print the value of these indexes we do as follow:\n",
    "X_train_np[0][2381]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19f6ddbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check other index:\n",
    "X_train_np[0][2964]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b4e4505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445     HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYARO...\n",
       "2905    HI DARLIN I HOPE YOU HAD A NICE NIGHT I WISH I...\n",
       "1266    Im in inperialmusic listening2the weirdest tra...\n",
       "3498    Oh, the grand is having a bit of a party but i...\n",
       "2911       How do you guys go to see movies on your side.\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first five samples in X_train is:\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8df9880e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEY HEY WERETHE MONKEESPEOPLE SAY WE MONKEYAROUND! HOWDY GORGEOUS, HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE JEN XXX'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to see the first email text for which we displayed indexes, we supply the first index '445' to the array:\n",
    "X_train[:5][445]  # This will shows us the first email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9629ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doin'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now as we saw in line '[46]', for index '2381' we have 1 value, so now if we check that index in the CountVectorizer, the\n",
    "# out put word must be present in the comment displayed in cell '[51]'.\n",
    "v.get_feature_names_out()[2381]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d760898",
   "metadata": {},
   "source": [
    "* So the out put word is 'doin', which is present in the email displayed in the cell '[51]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f40dca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now the train and test sets are ready, next we build a ML model.\n",
    "# Here we use 'Naive Bayes' classifier.\n",
    "# Here we use MultinomialNB classifier.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "735942f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to evaluate the performance of the model, for that we use CountVectorizer 'v', and we transform the X_test, \n",
    "# because X_train is a simple email (word email), we need to convert it into CountVectorizer.\n",
    "X_test_cv = v.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eafefb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       970\n",
      "           1       0.98      0.90      0.94       145\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For evaluation purpose, here we use classification report. As our dataset wan imbalance for this reason we print F1-score.\n",
    "# If your dataset is balanced, then you can print the accuracy of the model.\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test_cv)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ba6b3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can do some testing on the model:\n",
    "emails = [\n",
    "    'Hey mohan, can we get together to watch footbal game tomorrow?',\n",
    "    'Upto 20% discount on parking, exclusive offer just for you. Dont miss this reward!'\n",
    "]\n",
    "\n",
    "emails_count = v.transform(emails)\n",
    "model.predict(emails_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2187de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can also train the model very easily using sklearn pipeline.\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c0ba609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()), ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we can train the model.\n",
    "# See here we don't suppy X_train_cv or t_train_cv, because we apply CountVectorizer in the pipeline.\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0d99d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       970\n",
      "           1       0.98      0.90      0.94       145\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now again to see the classification report on the new trained model using sklearn pipeline:\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab84a7",
   "metadata": {},
   "source": [
    "**A beatiful exercise is given...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
