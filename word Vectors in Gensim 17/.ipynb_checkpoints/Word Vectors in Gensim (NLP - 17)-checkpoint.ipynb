{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63113af",
   "metadata": {},
   "source": [
    "## Word Vectors in Gensim Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b5b34",
   "metadata": {},
   "source": [
    "* **Gensim** is an NLP library similar to Spacy, but it's mainly using for topic modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef580b59",
   "metadata": {},
   "source": [
    "* All gensim models are listed on this page: https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b96ed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# From 'Gensim' library will import the appropraiate word vector.\n",
    "from gensim import downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300') # Here we specify which dataset or which kind of word embedding you want to \n",
    "                                           # download. So one of the word embedding that is available in gensim is a model\n",
    "                                           # that is trained on Google news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259f6826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72915095"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So this model has a function called 'similarity', which can find the similarity between two words.\n",
    "wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472528f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.7291510105133057),\n",
       " ('bad', 0.7190051078796387),\n",
       " ('terrific', 0.6889115571975708),\n",
       " ('decent', 0.6837348341941833),\n",
       " ('nice', 0.6836092472076416),\n",
       " ('excellent', 0.6442928910255432),\n",
       " ('fantastic', 0.6407778263092041),\n",
       " ('better', 0.6120728850364685),\n",
       " ('solid', 0.5806034207344055),\n",
       " ('lousy', 0.5764203071594238)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is another function called 'most_similar' which will list you the list of similar words to the given word.\n",
    "wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ecb1e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Germany', 0.7901253700256348),\n",
       " ('Austria', 0.6026812791824341),\n",
       " ('German', 0.6004959940910339),\n",
       " ('Germans', 0.5851002931594849),\n",
       " ('Poland', 0.5847075581550598),\n",
       " ('Hungary', 0.5271855592727661),\n",
       " ('BBC_Tristana_Moore', 0.5249711275100708),\n",
       " ('symbol_RSTI', 0.5245768427848816),\n",
       " ('Belgium', 0.5221248269081116),\n",
       " ('Germnay', 0.5199405550956726)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can do mathematics with the vectors.\n",
    "# For examples Frence - Paris + Berlin = Germany  Or King - man + Woman = Queen\n",
    "# Let's see:\n",
    "wv.most_similar(positive=[\"France\", \"Berlin\"], negative=[\"Paris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa06a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Queen:\n",
    "wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5127aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It has another 'api' called 'doesnt_match', if you give set of keywords, it will tell you which keyword doesn't match with\n",
    "# others.\n",
    "wv.doesnt_match([\"facebook\", \"cat\", \"google\", \"microsoft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2246a853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or \n",
    "wv.doesnt_match([\"dog\", \"cat\", \"google\", \"mouse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd15bba",
   "metadata": {},
   "source": [
    "### Gensim: Glove\n",
    "Stanford's page on GloVe: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22361979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Let's download another model called 'glove-twitter-25'.\n",
    "glv = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4d479b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('too', 0.9648016691207886),\n",
       " ('day', 0.9533665180206299),\n",
       " ('well', 0.9503170847892761),\n",
       " ('nice', 0.9438973665237427),\n",
       " ('better', 0.9425962567329407),\n",
       " ('fun', 0.941892683506012),\n",
       " ('much', 0.9413353800773621),\n",
       " ('this', 0.9387555122375488),\n",
       " ('hope', 0.9383508563041687),\n",
       " ('great', 0.9378516674041748)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now when we execute the 'most_similar' api, it's giving us different result. Because it gives result based on Twitter.\n",
    "glv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ed0c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twitter', 0.9480051398277283),\n",
       " ('google', 0.9231430888175964),\n",
       " ('instagram', 0.9184154272079468),\n",
       " ('internet', 0.9143875241279602),\n",
       " ('youtube', 0.9113808274269104),\n",
       " ('tumblr', 0.9077149033546448),\n",
       " ('link', 0.8995786905288696),\n",
       " ('fb', 0.8734269142150879),\n",
       " ('post', 0.8671452403068542),\n",
       " ('site', 0.8642723560333252)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...\n",
    "glv.most_similar(\"facebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d37174a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 'doesnt_match' method:\n",
    "glv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393cc7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...\n",
    "glv.doesnt_match(\"facebook cat google microsoft\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d54a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...\n",
    "\n",
    "glv.doesnt_match(\"banana grapes orange human\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f96d7",
   "metadata": {},
   "source": [
    "* Now we're probably getting an idea that there are trained word vectors available on the internet and different libraries such as **Spacy**, **Gensim**, **Pytorch**. You can load those vectors using these libraries. And then when you talk about **word2Vec**, and **Glove**, so these are all techniques (algorithms).\n",
    "* And when you see like 'glove-twitter-25', so it's simple composed of two terms: 'glove' mean algorithm and 'twitter-25' means the dataset on which 'glove' is trained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
