{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179bb0aa",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)\n",
    "**Named entity recognition (NER)** is a natural language processing (NLP) technique that involves identifying and categorizing named entities in text, such as people, organizations, locations, and dates. NER is an important step in many NLP applications that require extracting relevant information from unstructured text data.\n",
    "\n",
    "**Named entity recognition (NER)** is a subtask of natural language processing (NLP) that involves identifying and classifying named entities in text into predefined categories such as person names, organization names, locations, dates, and other entities. NER is an important step in many NLP applications such as information extraction, question answering, and machine translation. The goal of NER is to automatically identify and extract relevant information from unstructured text data, which can then be used to enhance various downstream tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e611f7",
   "metadata": {},
   "source": [
    "**Som real life usecases of NER is listed bellow:**\n",
    "   1. **Search:** We see search box in every website to find our needed information quickly. To know about specific companies mentioned in a huge text.\n",
    "   2. **Recommendation:** This is associated with the first one (search), it means based on search we propose related documents. The new contents will be suggested based on what you read and watched previously.\n",
    "   3. **Customer Care:** When we received different documents from customers, we can classify it based on topics they're talking about and sent it to relavant support team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215e3c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first load the spacy library and spacy English pre-trained model:\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c09b9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we want to explore NER support in spacy.\n",
    "# To see the components in the model:\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a41d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "Twitter Co  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "$45 billion  |  MONEY  |  Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "# So here we see the 'ner' component. So we'll see how this particular component work?\n",
    "# Let's have a simple text and recognize the entities in this text.\n",
    "doc = nlp(\"Tesla Inc is going to acquire Twitter Co for $45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b7daa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter Co\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can use 'displacy' to visually render the same thigns.\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c721b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To knows which entities are supported by spacy with the loaded pre-trained model:\n",
    "nlp.pipe_labels['ner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9569634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Bloomberg | PERSON | People, including fictional\n",
      "Bloomberg Inc | ORG | Companies, agencies, institutions, etc.\n",
      "1982 | DATE | Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "# Let's have another example:\n",
    "doc = nlp(\"Michael Bloomberg founded Bloomberg Inc in 1982\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d77f9346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Michael Bloomberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " founded \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bloomberg Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1982\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For better visualization:\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ae9322",
   "metadata": {},
   "source": [
    "* **Hugging face** is a popular machine learning NLP library. It has some BERT based named entity recognization. \n",
    "https://huggingface.co/dslim/bert-base-NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c462c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla  |  ORG\n",
      "Twitter Inc.  |  ORG\n",
      "$45 billion  |  MONEY\n"
     ]
    }
   ],
   "source": [
    "# So we might want to set a custome entity, for example in the following text, companies are recognizes by the\n",
    "# pre-trained model, but we think it's not recognized and we manually define it to 'spacy'.\n",
    "doc = nlp(\"Tesla is going to acquire Twitter Inc. for $45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72057b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So if we check the type of each token, it will be span.\n",
    "type(doc[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8cb3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can import 'Spam' class and manually assigns labels to the tokens.\n",
    "from spacy.tokens import Span\n",
    "\n",
    "s1 = Span(doc, 0, 1, label=\"Com\")              # the label is assigned to index 0 which has 'Tesla' word.\n",
    "s2 = Span(doc, 5, 6, label=\"Com\")              # the label is assigned to index 5 which has 'Twitter' word.\n",
    "doc.set_ents([s1, s2], default=\"unmodified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30eb280c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla  |  Com\n",
      "Twitter  |  Com\n",
      "Inc.  |  ORG\n",
      "$45 billion  |  MONEY\n"
     ]
    }
   ],
   "source": [
    "# Now to print the labels:\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \" | \", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e074660",
   "metadata": {},
   "source": [
    "### How can I build my own NER?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803f1da",
   "metadata": {},
   "source": [
    "The first approach to build our own NER is **Simple Lookup.** You can have a database of locations, companies, persons... and as you get more locations, companies in your vocabulary, you have a process where an operator manually add those entities into the databases. Then when you look to the text, you simply make comparsion. This approach is looking to be very stupid and naive but it works. Most people use it. It depends for your usecase, may be for your usecase it work better and will be best idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97e85b",
   "metadata": {},
   "source": [
    "<img src = \"img.jpg\" width = \"400px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392b628",
   "metadata": {},
   "source": [
    "The second approach is **Rule based NER.** This work based on some defined rules. We saw this already in spacy that when a word followed by Inc or Co it was recognizting to be company. Spacy provide a class called **EntityRuler** and could be use to define rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1282cc4",
   "metadata": {},
   "source": [
    "<img src = \"img1.jpg\" width = \"600px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8809be3",
   "metadata": {},
   "source": [
    "The **3rd** approach is **Machine Learning** where you can use a technique called Conditional Random Fields (CRF) and as well as BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982d214",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER): Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3c528",
   "metadata": {},
   "source": [
    "* **Excersie: 1**\n",
    "\n",
    "    Extract all the Geographical (cities, Countries, states) names from a given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47a054b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Kiran want to know the famous foods in each state of India. So, he opened Google and search for this question. Google showed that\n",
    "in Delhi it is Chaat, in Gujarat it is Dal Dhokli, in Tamilnadu it is Pongal, in Andhrapradesh it is Biryani, in Assam it is Papaya Khar,\n",
    "in Bihar it is Litti Chowkha and so on for all other states\"\"\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861b012",
   "metadata": {},
   "source": [
    "* **Expected Output:**\n",
    "\n",
    "   Geographical location Names: [India, Delhi, Gujarat, Tamilnadu, Andhrapradesh, Assam, Bihar]\n",
    "\n",
    "   Count: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a32aea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So first to know which labels we have for Person names and Dates we can find them from:\n",
    "nlp.pipe_labels['ner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a655d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So first to find geographical locations, we first define an array which stores the locations, next throught loop we go \n",
    "# through over the text.\n",
    "geo_names = []\n",
    "for entity in doc.ents:\n",
    "    if entity.label_ == 'GPE':     \n",
    "        geo_names.append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e281a626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[India, Delhi, Gujarat, Tamilnadu, Pongal, Andhrapradesh, Assam, Bihar]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next we can print the geographical locations names:\n",
    "geo_names   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8bc90d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next to count them, we simply find the lenght of the locations:\n",
    "len(geo_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47d94f",
   "metadata": {},
   "source": [
    "* **Excersie: 2**\n",
    "    \n",
    "  Extract all the birth dates of cricketers in the given Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b954912",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Sachin Tendulkar was born on 24 April 1973, Virat Kholi was born on 5 November 1988, Dhoni was born on 7 July 1981\n",
    "and finally Ricky ponting was born on 19 December 1974.\"\"\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e49ae",
   "metadata": {},
   "source": [
    "* **Expected Output:**\n",
    "\n",
    "    All Birth Dates: [24 April 1973, 5 November 1988, 7 July 1981, 19 December 1974]\n",
    "   \n",
    "    Count: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a74890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as geographical locations, we just compare the entities labels with the 'Date' and store then in an array.\n",
    "player_birth_dates = []\n",
    "for entity in doc.ents:\n",
    "    if entity.label_ == 'DATE':     \n",
    "        player_birth_dates.append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89fe4745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24 April 1973, 5 November 1988, 7 July 1981, 19 December 1974]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next we simply print the birth dates:\n",
    "player_birth_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2c92a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again to count them, we simply take their lengths:\n",
    "len(player_birth_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e97875",
   "metadata": {},
   "source": [
    "* **Thats were all for this session.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
