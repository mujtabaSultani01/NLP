{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ee99ee",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "**Stop words** in NLP (Natural Language Processing) refer to words that are commonly used in a language but do not carry any significant meaning or value in the analysis of text data. These words are usually removed from the text data during preprocessing as they do not add any value to the analysis and may even cause noise in the results. Examples of stop words in English include \"the,\" \"and,\" \"a,\" \"an,\" \"in,\" \"of,\" etc. Removing stop words helps in reducing the size of the data and improves the accuracy of text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826fcd68",
   "metadata": {},
   "source": [
    "* As we know, when we do bag of words for multiple commercial documents, then we can find which document is going to talk about specific company. But we have some words which don't help us in finding this truth that n1 documents is talking about Tesla company. So these words are called **Stop Words**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7b290",
   "metadata": {},
   "source": [
    "<img src = \"img.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3520d6",
   "metadata": {},
   "source": [
    "<img src = \"img1.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50d034",
   "metadata": {},
   "source": [
    "* So by removing the stop words we can less sparce our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ce76d",
   "metadata": {},
   "source": [
    "* NLP analyst remove the stop words for majority of times, but in some cases there is need to have stop words in our vocabulary, so in those cases we don't remove stop words. The most important case where we don't remove the stop words is **Sentiment Analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82602730",
   "metadata": {},
   "source": [
    "<img src = \"img2.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e420c9b5",
   "metadata": {},
   "source": [
    "* Next is **sentence translation** where we can't remove the stop words. See the following example if we remove the stop words from a sentence 'How are you doing Dhaval?', we will just have Dhaval which can't give the scense of the sentence and can't be translated to other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78750280",
   "metadata": {},
   "source": [
    "<img src = \"img3.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514a300",
   "metadata": {},
   "source": [
    "* Next is **Chat box.** If we remove the stop words it will doesn't give proper scense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2b546",
   "metadata": {},
   "source": [
    "<img src = \"img4.png\" width = \"800px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b7936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So first we import the spacy library and import check all the stop words which are include in the English model:\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "len(STOP_WORDS)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9474a4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To see the stop words:\n",
    "# STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117ec670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "just\n",
      "our\n",
      "the\n",
      "part\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "# Now let's import the spacy english pipeline and define a simple document and search for stop words.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"We just opened our wings, the flying part is coming soon\")\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da317737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So to remove the stop words from the document, we define the function to take a document and return clean text without \n",
    "# stop words:\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop]\n",
    "    return no_stop_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab8464d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['opened', 'wings', ',', 'flying', 'coming', 'soon']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We pass the text into the function here:\n",
    "preprocess(\"We just opened our wings, the flying part is coming soon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96be1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can see things like comma in the upper cell, so  to remove it we say that if it's not a punctuation mark. \n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59817fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['opened', 'wings', 'flying', 'coming', 'soon']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now again we pass the text:\n",
    "preprocess(\"We just opened our wings, the flying part is coming soon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccf13556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to display the return text as simple text not as list, we can do:\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(no_stop_words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1fb811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Musk wants time prepare trial'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing the text:\n",
    "preprocess(\"Musk wants time to prepare for a trial over his\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb4168",
   "metadata": {},
   "source": [
    "**Remove stop words from pandas dataframe text column**\n",
    "Dataset is downloaded from: https://www.kaggle.com/datasets/jbencina/department-of-justice-20092018-press-releases It contains press releases of different court cases from depart of justice (DOJ). The releases contain information such as outcomes of criminal cases, notable actions taken against felons, or other updates about the current administration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fedbac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13087, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now how to apply this pre-process function into 'Pandas DataFrame'? As we know commonly we load our dataset into Pandas \n",
    "# DataFrame and then we build an NLP model. Now if we want to do preprocessing on the DataFrame, so how to do that?\n",
    "# So here we have a json file which has justice related text. So we want to load it into a DataFrame.\n",
    "import pandas as pd\n",
    "df = pd.read_json(\"doj_press.json\",lines=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "675c074f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>17-773</td>\n",
       "      <td>Clinical Psychologist and Owner of Psychologic...</td>\n",
       "      <td>Two owners of psychological services companies...</td>\n",
       "      <td>2017-07-14T00:00:00-04:00</td>\n",
       "      <td>[Health Care Fraud]</td>\n",
       "      <td>[Criminal Division, USAO - Louisiana, Eastern]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>16-1341</td>\n",
       "      <td>Nevada Woman Indicted For Evading Payment of T...</td>\n",
       "      <td>Concealed Personal Funds and Assets from IRS C...</td>\n",
       "      <td>2016-11-16T00:00:00-05:00</td>\n",
       "      <td>[Tax]</td>\n",
       "      <td>[Tax Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>18-13</td>\n",
       "      <td>Former CFO of Arthrocare Corporation Sentenced...</td>\n",
       "      <td>The former chief financial officer (CFO) of Ar...</td>\n",
       "      <td>2018-01-05T00:00:00-05:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Criminal Division, USAO - Texas, Western]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11146</th>\n",
       "      <td>16-1116</td>\n",
       "      <td>Syrian Electronic Army Hacker Pleads Guilty</td>\n",
       "      <td>Peter Romar, 37, a Syrian national affiliated ...</td>\n",
       "      <td>2016-09-28T00:00:00-04:00</td>\n",
       "      <td>[Counterintelligence and Export Control, Finan...</td>\n",
       "      <td>[National Security Division (NSD), USAO - Virg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11913</th>\n",
       "      <td>15-725</td>\n",
       "      <td>Two Georgia Sisters-in-Law and Former Tax Retu...</td>\n",
       "      <td>Two Georgia sisters-in-law were sentenced toda...</td>\n",
       "      <td>2015-06-10T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Tax Division]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "1672    17-773  Clinical Psychologist and Owner of Psychologic...   \n",
       "8980   16-1341  Nevada Woman Indicted For Evading Payment of T...   \n",
       "3727     18-13  Former CFO of Arthrocare Corporation Sentenced...   \n",
       "11146  16-1116        Syrian Electronic Army Hacker Pleads Guilty   \n",
       "11913   15-725  Two Georgia Sisters-in-Law and Former Tax Retu...   \n",
       "\n",
       "                                                contents  \\\n",
       "1672   Two owners of psychological services companies...   \n",
       "8980   Concealed Personal Funds and Assets from IRS C...   \n",
       "3727   The former chief financial officer (CFO) of Ar...   \n",
       "11146  Peter Romar, 37, a Syrian national affiliated ...   \n",
       "11913  Two Georgia sisters-in-law were sentenced toda...   \n",
       "\n",
       "                            date  \\\n",
       "1672   2017-07-14T00:00:00-04:00   \n",
       "8980   2016-11-16T00:00:00-05:00   \n",
       "3727   2018-01-05T00:00:00-05:00   \n",
       "11146  2016-09-28T00:00:00-04:00   \n",
       "11913  2015-06-10T00:00:00-04:00   \n",
       "\n",
       "                                                  topics  \\\n",
       "1672                                 [Health Care Fraud]   \n",
       "8980                                               [Tax]   \n",
       "3727                                                  []   \n",
       "11146  [Counterintelligence and Export Control, Finan...   \n",
       "11913                                                 []   \n",
       "\n",
       "                                              components  \n",
       "1672      [Criminal Division, USAO - Louisiana, Eastern]  \n",
       "8980                                      [Tax Division]  \n",
       "3727          [Criminal Division, USAO - Texas, Western]  \n",
       "11146  [National Security Division (NSD), USAO - Virg...  \n",
       "11913                                     [Tax Division]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print 5 records from the json file:\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20691db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So let's say we're building a model to auto extract topics. It means our NLP application will auto-extract the topics from\n",
    "# the text. We filter all the articles.\n",
    "# So to see the type to the topics:\n",
    "type(df.topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c572bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12810</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "      <td>13087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12672</td>\n",
       "      <td>12887</td>\n",
       "      <td>13080</td>\n",
       "      <td>2400</td>\n",
       "      <td>253</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>13-526</td>\n",
       "      <td>Northern California Real Estate Investor Agree...</td>\n",
       "      <td>WASHINGTON – ING Bank N.V., a financial inst...</td>\n",
       "      <td>2018-04-13T00:00:00-04:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Criminal Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>8399</td>\n",
       "      <td>2680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "count    12810                                              13087   \n",
       "unique   12672                                              12887   \n",
       "top     13-526  Northern California Real Estate Investor Agree...   \n",
       "freq         3                                                  8   \n",
       "\n",
       "                                                 contents  \\\n",
       "count                                               13087   \n",
       "unique                                              13080   \n",
       "top       WASHINGTON – ING Bank N.V., a financial inst...   \n",
       "freq                                                    2   \n",
       "\n",
       "                             date topics           components  \n",
       "count                       13087  13087                13087  \n",
       "unique                       2400    253                  810  \n",
       "top     2018-04-13T00:00:00-04:00     []  [Criminal Division]  \n",
       "freq                           20   8399                 2680  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see the type ofthe topics is list.\n",
    "# To see some exploration on the dataset:\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "673ccfd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-1412</td>\n",
       "      <td>14 Indicted in Connection with New England Com...</td>\n",
       "      <td>A 131-count criminal indictment was unsealed t...</td>\n",
       "      <td>2014-12-17T00:00:00-05:00</td>\n",
       "      <td>[Consumer Protection]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-1419</td>\n",
       "      <td>2017 Southeast Regional Animal Cruelty Prosecu...</td>\n",
       "      <td>The United States Attorney’s Office for the Mi...</td>\n",
       "      <td>2017-12-14T00:00:00-05:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15-1562</td>\n",
       "      <td>21st Century Oncology to Pay $19.75 Million to...</td>\n",
       "      <td>21st Century Oncology LLC, has agreed to pay $...</td>\n",
       "      <td>2015-12-18T00:00:00-05:00</td>\n",
       "      <td>[False Claims Act, Health Care Fraud]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17-1404</td>\n",
       "      <td>21st Century Oncology to Pay $26 Million to Se...</td>\n",
       "      <td>21st Century Oncology Inc. and certain of its ...</td>\n",
       "      <td>2017-12-12T00:00:00-05:00</td>\n",
       "      <td>[Health Care Fraud, False Claims Act]</td>\n",
       "      <td>[Civil Division, USAO - Florida, Middle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "4    18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "7   14-1412  14 Indicted in Connection with New England Com...   \n",
       "19  17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
       "22  15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
       "23  17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
       "\n",
       "                                             contents  \\\n",
       "4   The U.S. Department of Justice, the U.S. Envir...   \n",
       "7   A 131-count criminal indictment was unsealed t...   \n",
       "19  The United States Attorney’s Office for the Mi...   \n",
       "22  21st Century Oncology LLC, has agreed to pay $...   \n",
       "23  21st Century Oncology Inc. and certain of its ...   \n",
       "\n",
       "                         date                                 topics  \\\n",
       "4   2018-07-09T00:00:00-04:00                          [Environment]   \n",
       "7   2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
       "19  2017-12-14T00:00:00-05:00                          [Environment]   \n",
       "22  2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
       "23  2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
       "\n",
       "                                           components  \n",
       "4        [Environment and Natural Resources Division]  \n",
       "7                                    [Civil Division]  \n",
       "19  [Environment and Natural Resources Division, U...  \n",
       "22                                   [Civil Division]  \n",
       "23           [Civil Division, USAO - Florida, Middle]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the topics type is list and we want to filter it using a condition at the square brackets.\n",
    "# So the condition is, whenever the topics list is empty, filter that.\n",
    "df = df[df[\"topics\"].str.len() != 0] # This will filter out all the rows which has empty list in the topics.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea4d5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4688, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After filtering if we check the DataFrame shape:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f63d40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So here our main goal is to apply the preprocess function into Pandas DataFrame column.\n",
    "# To keep thing simple, we create a small DataFrame from the top 100 rows:\n",
    "df =df.head(100)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5be550b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21st Century Oncology Inc. and certain of its subsidiaries and affiliates have agreed to pay $26 million to the government to resolve a self-disclosure relating to the submission of false attestations regarding the company’s use of electronic health records software and separate allegations that they violated the False Claims Act by submitting, or causing the submission of, claims for certain services provided pursuant to referrals from physicians with whom they had improper financial relationships. \\xa0 “The Justice Department is committed to zealously investigating improper financial relationships that have the potential to compromise physicians’ medical judgment,” said Acting Assistant Attorney General Chad A. Readler of the Justice Department’s Civil Division.\\xa0 “However, we will work with companies that accept responsibility for their past compliance failures and promptly take corrective action.”  \\xa0 21st Century Oncology, which is headquartered in Fort Myers, Florida, owns and operates subsidiaries and affiliates throughout the United States that provide integrated cancer care.\\xa0 As part of its business, 21st Century Oncology’s subsidiaries and affiliates employ physicians in specialty fields such as radiation oncology, medical oncology, and urology.\\xa0  \\xa0 The settlement announced today resolves conduct that was self-disclosed by the company regarding payments made by the government as part of the Medicare Electronic Health Records (EHR) Incentive Program.\\xa0 Under the Medicare EHR Incentive Program, physicians who attest to their meaningful use of certified EHR technology may receive incentive payments and avoid downward adjustments to certain Medicare claims.\\xa0 As part of its self-disclosure, 21st Century Oncology reported that it knowingly submitted, or caused the submission of, false attestations to CMS concerning employed physicians’ use of EHR software.\\xa0 The company further reported that, in support of the attestations, its employees falsified data regarding the company’s use of EHR software, fabricated software utilization reports, and superimposed EHR vendor logos onto the reports to make them look legitimate.\\xa0  \\xa0 “This settlement represents our office’s continued commitment to ensuring compliance with important federal health care laws,” said Acting U.S. Attorney Stephen Muldrow of the Middle District of Florida.\\xa0 “We appreciate that 21st Century Oncology self-reported a major fraud affecting Medicare, and we are also pleased that the company has agreed to accept financial responsibility for past compliance failures.” \\xa0 The settlement also resolves the government’s allegations regarding violations of the physician self-referral law (commonly referred to as the “Stark Law.”)\\xa0 The Stark Law prohibits an entity from submitting claims to Medicare for designated health services performed pursuant to referrals from physicians with whom the entity has a financial relationship unless certain designated exceptions apply.\\xa0 The government alleged that 21st Century Oncology and certain of its subsidiaries and affiliates violated the FCA by submitting, or causing the submission of, claims for services performed pursuant to referrals from physicians whose compensation did not satisfy any exception to the Stark Law. \\xa0 The Stark Law allegations were originally brought in a lawsuit filed by Matthew Moore, 21st Century Oncology’s former Interim Vice President of Financial Planning, under the qui tam provisions of the False Claims Act.\\xa0 Under the Act, private parties may bring suit on behalf of the government and share in any recovery.\\xa0 Mr. Moore will receive $2,000,000 as his share of the recovery associated with the Stark Law allegations. \\xa0 In addition to the civil settlement, 21st Century Oncology has entered into a new five-year Corporate Integrity Agreement with the Office of Inspector General of the United States Department of Health and Human Services (HHS-OIG), which obligates 21st Century Oncology to undertake substantial internal compliance reforms, including hiring independent review organizations to conduct annual claims and arrangements reviews.\\xa0 \\xa0 “21st Century Oncology admitted to causing violation of the meaningful use regulations in order to fund an electronic health records system, as well as falsifying records to cover up those actions,” said Shimon R. Richmond, Special Agent in Charge for the Office of Inspector General of the U.S. Department of Health and Human Services.\\xa0 “Separately, the government alleged that same company, through its affiliates and subsidiaries, caused certain physicians to enter into illegal financial arrangements.\\xa0 Providers engaging in similar behavior should expect attention from OIG.”\\xa0\\xa0\\xa0 \\xa0 The government’s resolution of this matter illustrates the government’s emphasis on combating health care fraud.\\xa0 Tips and complaints from all sources about potential fraud, waste, abuse, and mismanagement can be reported to the Department of Health and Human Services at 900-HHS-TIPS (800-447-8477). \\xa0 The investigation was handled by the Civil Division’s Commercial Litigation Branch and the Fort Myers Division of\\xa0the U.S. Attorney’s Office for the Middle District of Florida, with assistance from the U.S. Attorney’s Office for the Southern District of New York and HHS-OIG.\\xa0 The claims resolved by this settlement are allegations only; there has been no determination of liability.\\xa0 The case is captioned United States ex rel. Moore v. 21st Century Oncology, LLC, No. 2:16-cv-99 (M.D. Fl.).'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now on the contents column of the DataFrame we apply preprocess function to remove all the stop words and return the \n",
    "# remained words. From remain words then we can build a simple NLP application.\n",
    "# So if we see the first row of the 'contents' column:\n",
    "df.contents.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fb9feb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6286"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we check the lenght of this row, it would be a big lenght, we want to remove the stop words from these rows:\n",
    "len(df.contents.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ae0adfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>date</th>\n",
       "      <th>topics</th>\n",
       "      <th>components</th>\n",
       "      <th>contents_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18-898</td>\n",
       "      <td>$100 Million Settlement Will Speed Cleanup Wor...</td>\n",
       "      <td>The U.S. Department of Justice, the U.S. Envir...</td>\n",
       "      <td>2018-07-09T00:00:00-04:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division]</td>\n",
       "      <td>U.S. Department Justice U.S. Environmental Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-1412</td>\n",
       "      <td>14 Indicted in Connection with New England Com...</td>\n",
       "      <td>A 131-count criminal indictment was unsealed t...</td>\n",
       "      <td>2014-12-17T00:00:00-05:00</td>\n",
       "      <td>[Consumer Protection]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>131 count criminal indictment unsealed today B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-1419</td>\n",
       "      <td>2017 Southeast Regional Animal Cruelty Prosecu...</td>\n",
       "      <td>The United States Attorney’s Office for the Mi...</td>\n",
       "      <td>2017-12-14T00:00:00-05:00</td>\n",
       "      <td>[Environment]</td>\n",
       "      <td>[Environment and Natural Resources Division, U...</td>\n",
       "      <td>United States Attorney Office Middle District ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15-1562</td>\n",
       "      <td>21st Century Oncology to Pay $19.75 Million to...</td>\n",
       "      <td>21st Century Oncology LLC, has agreed to pay $...</td>\n",
       "      <td>2015-12-18T00:00:00-05:00</td>\n",
       "      <td>[False Claims Act, Health Care Fraud]</td>\n",
       "      <td>[Civil Division]</td>\n",
       "      <td>21st Century Oncology LLC agreed pay $ 19.75 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17-1404</td>\n",
       "      <td>21st Century Oncology to Pay $26 Million to Se...</td>\n",
       "      <td>21st Century Oncology Inc. and certain of its ...</td>\n",
       "      <td>2017-12-12T00:00:00-05:00</td>\n",
       "      <td>[Health Care Fraud, False Claims Act]</td>\n",
       "      <td>[Civil Division, USAO - Florida, Middle]</td>\n",
       "      <td>21st Century Oncology Inc. certain subsidiarie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "4    18-898  $100 Million Settlement Will Speed Cleanup Wor...   \n",
       "7   14-1412  14 Indicted in Connection with New England Com...   \n",
       "19  17-1419  2017 Southeast Regional Animal Cruelty Prosecu...   \n",
       "22  15-1562  21st Century Oncology to Pay $19.75 Million to...   \n",
       "23  17-1404  21st Century Oncology to Pay $26 Million to Se...   \n",
       "\n",
       "                                             contents  \\\n",
       "4   The U.S. Department of Justice, the U.S. Envir...   \n",
       "7   A 131-count criminal indictment was unsealed t...   \n",
       "19  The United States Attorney’s Office for the Mi...   \n",
       "22  21st Century Oncology LLC, has agreed to pay $...   \n",
       "23  21st Century Oncology Inc. and certain of its ...   \n",
       "\n",
       "                         date                                 topics  \\\n",
       "4   2018-07-09T00:00:00-04:00                          [Environment]   \n",
       "7   2014-12-17T00:00:00-05:00                  [Consumer Protection]   \n",
       "19  2017-12-14T00:00:00-05:00                          [Environment]   \n",
       "22  2015-12-18T00:00:00-05:00  [False Claims Act, Health Care Fraud]   \n",
       "23  2017-12-12T00:00:00-05:00  [Health Care Fraud, False Claims Act]   \n",
       "\n",
       "                                           components  \\\n",
       "4        [Environment and Natural Resources Division]   \n",
       "7                                    [Civil Division]   \n",
       "19  [Environment and Natural Resources Division, U...   \n",
       "22                                   [Civil Division]   \n",
       "23           [Civil Division, USAO - Florida, Middle]   \n",
       "\n",
       "                                         contents_new  \n",
       "4   U.S. Department Justice U.S. Environmental Pro...  \n",
       "7   131 count criminal indictment unsealed today B...  \n",
       "19  United States Attorney Office Middle District ...  \n",
       "22  21st Century Oncology LLC agreed pay $ 19.75 m...  \n",
       "23  21st Century Oncology Inc. certain subsidiarie...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So to remove stop words from 'contents' column, first we create a new column from the existance 'contents' column and then\n",
    "# we apply preprocess to the 'apply()'' function. We don't want array to be back, we want to string to be back. So for that \n",
    "# we already use the 'join()' function with double qutation in cell '[14]'.\n",
    "df[\"contents_new\"] = df.contents.apply(preprocess)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57eab8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. Department Justice U.S. Environmental Protection Agency EPA Rhode Island Department Environmental Management RIDEM announced today subsidiaries Stanley Black Decker Inc.—Emhart Industries Inc. Black Decker Inc.—have agreed clean dioxin contaminated sediment soil Centredale Manor Restoration Pro'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we see in the new created column 'contents_new' we don't have stop words, it's removed. To check, let's see the \n",
    "# first one:\n",
    "df.contents_new.iloc[0][:300]  # Will print first 300 charecters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbed8269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6286, 4574)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And when you compared the lenght of this first row of 'contents_new' column with the 'contents' column, it will be small:\n",
    "len(df.contents.iloc[0]), len(df.contents_new.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e6ffb",
   "metadata": {},
   "source": [
    "**Examples where removing stop words can create a problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0bf58",
   "metadata": {},
   "source": [
    "**1. Sentiment detection: Not always but in some cases, based on your dataset it can change the sentiment of a sentence if you remove stop words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42b99142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good movie'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"this is a good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57cccb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good movie'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"this is not a good movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efff0c9",
   "metadata": {},
   "source": [
    "**2. Language translation: Say you want to translate following sentence from english to telugu. Before actual translation if you remove stop words and then translate, it will produce horrible result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd9f35c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dhaval'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"how are you doing dhaval?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c380c2a",
   "metadata": {},
   "source": [
    "**3. Chat bot or any Q&A system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f4b11d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find yoga mat website help'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"I don't find yoga mat on your website. Can you help?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
