{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ee8c4c",
   "metadata": {},
   "source": [
    "## TF-IDF Text Representation\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** is a statistical measure used to evaluate the importance of a word in a document or corpus. It is a numerical representation of how relevant a term is in a given document or corpus.\n",
    "\n",
    "The **TF-IDF** score is calculated by multiplying the **term frequency (TF)** with the **inverse document frequency (IDF)**. The term frequency measures how frequently a term appears in a document, while the inverse document frequency measures how important a term is in the entire corpus. \n",
    "\n",
    "We use **TF-IDF** for text representation because it helps to identify the most important words in a document or corpus. By assigning higher weights to the most relevant terms, we can effectively summarize and categorize large amounts of text data. This can be useful in various applications such as **information retrieval, sentiment analysis**, and text **classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665383e",
   "metadata": {},
   "source": [
    "### What is TF-IDF?\n",
    "* TF stands for **Term Frequency** and denotes the ratio of number of times a particular word appeared in a Document to total number of words in the document.\n",
    "\n",
    "        Term Frequency(TF) = [number of times word appeared / total no of words in a document]\n",
    "\n",
    "\n",
    "* Term Frequency values ranges between 0 and 1. If a word occurs more number of times, then it's value will be close to 1.\n",
    "\n",
    "* IDF stands for **Inverse Document Frequency** and denotes the log of ratio of total number of documents/datapoints in the whole dataset to the number of documents that contains the particular word.\n",
    "\n",
    "        Inverse Document Frequency(IDF) = [log(Total number of documents / number of documents that contains the word)]\n",
    "\n",
    "* In IDF, if a word occured in more number of documents and is common across all documents, then it's value will be less and ratio will approaches to 0.\n",
    "\n",
    "#### Finally:\n",
    "\n",
    "          TF-IDF = Term Frequency(TF) * Inverse Document Frequency(IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fa5eb",
   "metadata": {},
   "source": [
    "<img src = \"img.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75150bb3",
   "metadata": {},
   "source": [
    "<img src = \"img1.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3e752",
   "metadata": {},
   "source": [
    "<img src = \"img2.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f044a",
   "metadata": {},
   "source": [
    "<img src = \"img3.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8894e",
   "metadata": {},
   "source": [
    "<img src = \"img4.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc11bda2",
   "metadata": {},
   "source": [
    "* Sklear uses slightely different formula for IDF to take into account the zero division possibility. They add constant 1 and in result they add 1 more time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d4419",
   "metadata": {},
   "source": [
    "<img src = \"img5.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b8015",
   "metadata": {},
   "source": [
    "* Now let's talk about why we use log with **IDF?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01008a",
   "metadata": {},
   "source": [
    "<img src = \"img6.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051da018",
   "metadata": {},
   "source": [
    "* The answer is taken from **Stack Overflow**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f575a17b",
   "metadata": {},
   "source": [
    "<img src = \"img7.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095823c3",
   "metadata": {},
   "source": [
    "<img src = \"img8.png\" width = \"800px\" height = \"600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38863cc",
   "metadata": {},
   "source": [
    "### Limitation of TF-IDF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e1f3f",
   "metadata": {},
   "source": [
    "* Similar to to previous model like **Bag of Words**, **Bag of n-grams** and **One Hot Encoding**, **TF-IDF** has the following limitations:\n",
    "    1. As n increased, dimensionality and sparsity increases.\n",
    "    2. Doesn't capture relationships between words.\n",
    "    3. Doesn't address Out Of Vocabulary (OOV) problem.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4d0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So for implementation of TF-IDF, first we import 'TfidfVectorizer':\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4400fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we take one sample corpus:\n",
    "corpus = [\n",
    "    \"Thor eating pizza, Loki is eating pizza, Ironman ate pizza already\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new surface tomorrow\",\n",
    "    \"Amazon is announcing new eco-dot tomorrow\",\n",
    "    \"I am eating biryani and you are eating grapes\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1a4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we create an instance of TfidfVectorizer class, and then fit the corpus and transform it. \n",
    "\n",
    "v = TfidfVectorizer()                   # TfidfVectorizer class instance\n",
    "v.fit(corpus)                           # calling fit() method to create vectors\n",
    "transform_output = v.transform(corpus)  # This complete the vector creation.\n",
    "\n",
    "# Instead of last two commands we can use ' transform_output = v.fit_transform(corpus)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc89e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thor': 25, 'eating': 10, 'pizza': 22, 'loki': 17, 'is': 16, 'ironman': 15, 'ate': 7, 'already': 0, 'apple': 5, 'announcing': 4, 'new': 20, 'iphone': 14, 'tomorrow': 26, 'tesla': 24, 'model': 19, 'google': 12, 'pixel': 21, 'microsoft': 18, 'surface': 23, 'amazon': 2, 'eco': 11, 'dot': 9, 'am': 1, 'biryani': 8, 'and': 3, 'you': 27, 'are': 6, 'grapes': 13}\n"
     ]
    }
   ],
   "source": [
    "# So now the v object got the vocabulary, so we can print the vocabulary:\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85feb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we supply 'v' to 'dir()', we'll see all the members:\n",
    "# dir(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50337258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already : 2.386294361119891\n",
      "am : 2.386294361119891\n",
      "amazon : 2.386294361119891\n",
      "and : 2.386294361119891\n",
      "announcing : 1.2876820724517808\n",
      "apple : 2.386294361119891\n",
      "are : 2.386294361119891\n",
      "ate : 2.386294361119891\n",
      "biryani : 2.386294361119891\n",
      "dot : 2.386294361119891\n",
      "eating : 1.9808292530117262\n",
      "eco : 2.386294361119891\n",
      "google : 2.386294361119891\n",
      "grapes : 2.386294361119891\n",
      "iphone : 2.386294361119891\n",
      "ironman : 2.386294361119891\n",
      "is : 1.1335313926245225\n",
      "loki : 2.386294361119891\n",
      "microsoft : 2.386294361119891\n",
      "model : 2.386294361119891\n",
      "new : 1.2876820724517808\n",
      "pixel : 2.386294361119891\n",
      "pizza : 2.386294361119891\n",
      "surface : 2.386294361119891\n",
      "tesla : 2.386294361119891\n",
      "thor : 2.386294361119891\n",
      "tomorrow : 1.2876820724517808\n",
      "you : 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "# To print the IDF score of each word, we need to either iterate through this particular directory 'v.vocabulary' or if we \n",
    "# want to go on sequence of the words and orderly get the word idf scores.\n",
    "# we'll follow the 2nd method:\n",
    "\n",
    "all_feature_names = v.get_feature_names_out()  # Will print all the words (vocabulary) in order.\n",
    "\n",
    "for word in all_feature_names:\n",
    "    \n",
    "    indx = v.vocabulary_.get(word)             # Will get the index for each word from vocabulary\n",
    "\n",
    "    idf_score = v.idf_[indx]                   # will get you the score of all words\n",
    "    \n",
    "    print(f\"{word} : {idf_score}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a4dfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thor eating pizza, Loki is eating pizza, Ironman ate pizza already',\n",
       " 'Apple is announcing new iphone tomorrow']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So from the scores we know that 'is' has less scores because it's common term and is repeated in majority of sentences \n",
    "# and it's not more important. But if you see 'Amazon', 'Tesla' or 'Apple', they have big scores, because they're important.\n",
    "# So now to print the whole 'TF-IDF' scores. before that let's see the first two sentences of the corpus:\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b4ec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24266547 0.         0.         0.         0.         0.\n",
      "  0.         0.24266547 0.         0.         0.40286636 0.\n",
      "  0.         0.         0.         0.24266547 0.11527033 0.24266547\n",
      "  0.         0.         0.         0.         0.72799642 0.\n",
      "  0.         0.24266547 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.30652086 0.5680354\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5680354  0.         0.26982671 0.\n",
      "  0.         0.         0.30652086 0.         0.         0.\n",
      "  0.         0.         0.30652086 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# So we want to print the coresponding 'TF-IDF' vectors for these two sentences.\n",
    "# So we know it's present in the transform_output.\n",
    "print(transform_output.toarray()[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1fce0",
   "metadata": {},
   "source": [
    "* So now if we check the 'is' TF-IDF score which is 0.11527033, is on index 17 (we know it from cell[7]) in the first sentence. The 'Thor' TF-IDF score is 0.24266547 which is more than 'is' scores. So we see based on importance of the words TF-IDF assigns the scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7650dd1",
   "metadata": {},
   "source": [
    "### Problem Statement: Given a description about a product sold on e-commerce website, classify it in one of the 4 categories\n",
    "Dataset Credits: https://www.kaggle.com/datasets/saurabhshahane/ecommerce-text-classification\n",
    "\n",
    "This data consists of two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ceb74f",
   "metadata": {},
   "source": [
    "<img src = \"img9.png\" width = \"900px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2f55a",
   "metadata": {},
   "source": [
    "* The **dataset** simply has two columns:\n",
    "* **Text**: Description of an item sold on e-commerce website\n",
    "* **Label**: Category of that item. Total 4 categories: \"Electronics\", \"Household\", \"Books\" and \"Clothing & Accessories\", which almost cover 80% of any E-commerce website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4337992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household\n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household\n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics\n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories\n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we import the pandas and read the dataset:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Ecommerce_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298123b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2)\n"
     ]
    }
   ],
   "source": [
    "# To see the shape of the dataset:\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c56b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Household                 6000\n",
       "Electronics               6000\n",
       "Clothing & Accessories    6000\n",
       "Books                     6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# T check the distribution of labels for imbalance issue: \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb476d8",
   "metadata": {},
   "source": [
    "* From the above, we can see that almost all the labels(classes) occured equal number of times and perfectly balanced. There is no problem of class imbalance and hence no need to apply any balancing techniques like undersampling, oversampling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedc9595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13400</th>\n",
       "      <td>Cooler Master Elite 130 Mini-ITX Computer Case...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5815</th>\n",
       "      <td>Younky Unisex Combo Of Uv Protected Aviator St...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>Farraige Lapcare Chillmate Ergonomic Laptop Co...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>Imation 4.7GB IMATION DVD RW 3 Pack Imation 4....</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>BRATS N BEAUTY - Army/Military Cap for BOY Nav...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "13400  Cooler Master Elite 130 Mini-ITX Computer Case...   \n",
       "5815   Younky Unisex Combo Of Uv Protected Aviator St...   \n",
       "16796  Farraige Lapcare Chillmate Ergonomic Laptop Co...   \n",
       "1343   Imation 4.7GB IMATION DVD RW 3 Pack Imation 4....   \n",
       "910    BRATS N BEAUTY - Army/Military Cap for BOY Nav...   \n",
       "\n",
       "                        label  label_num  \n",
       "13400             Electronics          2  \n",
       "5815   Clothing & Accessories          3  \n",
       "16796             Electronics          2  \n",
       "1343              Electronics          2  \n",
       "910    Clothing & Accessories          3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we add the 'labels' category into a new column with conversion to a number: \n",
    "\n",
    "df['label_num'] = df['label'].map({\n",
    "    'Household' : 0, \n",
    "    'Books': 1, \n",
    "    'Electronics': 2, \n",
    "    'Clothing & Accessories': 3\n",
    "})\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ded7e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we call to train_test_split method to split the dataset:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.Text, \n",
    "    df.label_num, \n",
    "    test_size=0.2,               # 80% samples will go to train dataset.\n",
    "    random_state=2022,\n",
    "    stratify=df.label_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22bfa50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (19200,)\n",
      "Shape of X_test:  (4800,)\n"
     ]
    }
   ],
   "source": [
    "# To see the shape of both train and test samples:\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8d1bec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4800\n",
       "2    4800\n",
       "3    4800\n",
       "1    4800\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see balance of y_train, we do as:\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "845f6484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1200\n",
       "2    1200\n",
       "3    1200\n",
       "1    1200\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same thing for y_test:\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b6109",
   "metadata": {},
   "source": [
    "**Attempt 1 :**\n",
    "\n",
    "    1. using sklearn pipeline module create a classification pipeline to classify the Ecommerce Data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "    * use TF-IDF for pre-processing the text.\n",
    "    * use KNN as the classifier\n",
    "    * print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f27db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1200\n",
      "           1       0.97      0.95      0.96      1200\n",
      "           2       0.97      0.97      0.97      1200\n",
      "           3       0.97      0.98      0.97      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we'll use few classifiers from 'sklearn' to train the model. First we'll use KNN, then RF and then NB. Just to check \n",
    "# the performance of difference classifiers...\n",
    "\n",
    "# Necesary libraries:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('KNN', KNeighborsClassifier())         \n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b23edf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20706    Lal Haveli Designer Handmade Patchwork Decorat...\n",
       "19166    GOTOTOP Classical Retro Cotton & PU Leather Ne...\n",
       "15209    FabSeasons Camouflage Polyester Multi Function...\n",
       "2462     Indian Superfoods: Change the Way You Eat Revi...\n",
       "6621     Milton Marvel Insulated Steel Casseroles, Juni...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see a few sentence from corpus:\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3736a81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20706    0\n",
       "19166    2\n",
       "15209    3\n",
       "2462     1\n",
       "6621     3\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the actual result for first five sentences as we displayed upper.\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "649ad548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our model prediction for first five samples:\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6fcf9",
   "metadata": {},
   "source": [
    "* So we see out of 5 we got three correct predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680c57e",
   "metadata": {},
   "source": [
    "* **Attempt 2 :**\n",
    "\n",
    "      1. using sklearn pipeline module create a classification pipeline to classify the Ecommerce Data.\n",
    "\n",
    "* **Note:**\n",
    "\n",
    "    * use TF-IDF for pre-processing the text.\n",
    "    * use **MultinomialNB** as the classifier.\n",
    "    * print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bb51668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1200\n",
      "           1       0.98      0.92      0.95      1200\n",
      "           2       0.97      0.97      0.97      1200\n",
      "           3       0.97      0.99      0.98      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So next we use 'MultinomialNB' classifier.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7361e40",
   "metadata": {},
   "source": [
    "* The result are looking almost similar..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cb445c",
   "metadata": {},
   "source": [
    "* **Attempt 3 :**\n",
    "\n",
    "    1. using sklearn pipeline module create a classification pipeline to classify the Ecommerce Data.\n",
    "\n",
    "* **Note:**\n",
    "\n",
    "    * use TF-IDF for pre-processing the text.\n",
    "    * use **Random Forest** as the classifier.\n",
    "    * print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e63613c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1200\n",
      "           1       0.98      0.98      0.98      1200\n",
      "           2       0.98      0.97      0.97      1200\n",
      "           3       0.98      0.99      0.98      1200\n",
      "\n",
      "    accuracy                           0.97      4800\n",
      "   macro avg       0.97      0.97      0.97      4800\n",
      "weighted avg       0.97      0.97      0.97      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next we try Random Fores:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),      \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56bcee",
   "metadata": {},
   "source": [
    "* So we see that the **Random Forest** classifier is giving us the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b10d4",
   "metadata": {},
   "source": [
    "* **Use text pre-processing to remove stop words, punctuations and apply lemmatization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "686a88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now when we trained the previous models we didn't remove stop words, lemmatizations and so on...\n",
    "# Here we will create a function wich preprocess the text and then we'll train the model again but usng preprocessed text.\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:  # remove the stop words and punctuations...\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_) # It convert word to its base form.\n",
    "    \n",
    "    return \" \".join(filtered_tokens)         # It will return simple preprocessed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8045c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a new column which will hold preprocessed text, and for that we apply 'apply()' function.\n",
    "df['preprocessed_txt'] = df['Text'].apply(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50697b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban Ladder Eisner low Study Office Computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "      <td>contrast live Wooden Decorative Box Painted Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "      <td>IO Crest SY PCI40010 PCI raid Host Controller ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>ISAKAA Baby Socks bear 8 Years- Pack 4 6 8 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "      <td>Indira Designer Women Art Mysore Silk Saree Bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label  \\\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household   \n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household   \n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics   \n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories   \n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories   \n",
       "\n",
       "   label_num                                   preprocessed_txt  \n",
       "0          0  Urban Ladder Eisner low Study Office Computer ...  \n",
       "1          0  contrast live Wooden Decorative Box Painted Bo...  \n",
       "2          2  IO Crest SY PCI40010 PCI raid Host Controller ...  \n",
       "3          3  ISAKAA Baby Socks bear 8 Years- Pack 4 6 8 12 ...  \n",
       "4          3  Indira Designer Women Art Mysore Silk Saree Bl...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's print few samples and see the changes:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf61506d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urban Ladder Eisner Low Back Study-Office Computer Chair(Black) A study in simple. The Eisner study chair has a firm foam cushion, which makes long hours at your desk comfortable. The flexible meshed back is designed for air-circulation and support when you lean back. The curved arms provide ergonomic forearm support. Adjust the height using the gas lift to find that comfortable position and the nylon castors make it easy to move around your space. Chrome legs refer to the images for dimension details any assembly required will be done by the UL team at the time of delivery indoor use only.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First sample from raw text:\n",
    "df.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "713bc7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urban Ladder Eisner low Study Office Computer Chair(Black study simple Eisner study chair firm foam cushion make long hour desk comfortable flexible mesh design air circulation support lean curved arm provide ergonomic forearm support adjust height gas lift find comfortable position nylon castor easy space chrome leg refer image dimension detail assembly require UL team time delivery indoor use'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First sample from preprocessed text:\n",
    "df.preprocessed_txt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adb5784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's again split the train and test samples of the preprocessed text for model training:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.preprocessed_txt, \n",
    "    df.label_num,\n",
    "    test_size=0.2, \n",
    "    random_state=2022,\n",
    "    stratify=df.label_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bc541bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1200\n",
      "           1       0.98      0.98      0.98      1200\n",
      "           2       0.98      0.97      0.98      1200\n",
      "           3       0.98      0.99      0.99      1200\n",
      "\n",
      "    accuracy                           0.98      4800\n",
      "   macro avg       0.98      0.98      0.98      4800\n",
      "weighted avg       0.98      0.98      0.98      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's again train the Random Forest classifier:\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),       \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4cae0",
   "metadata": {},
   "source": [
    "* If you compare above classification report with respect to **RandomForest** Model with the one from unprocessed text, you will find some improvement in the model that uses preprocessed cleaned up text. The F1 score improved in the case of preprocessed data. Hence we can conclude that for this particular problem using preprocessing (removing stop words, lemmatization) is improving the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccdfed",
   "metadata": {},
   "source": [
    "* **Plot confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c9c31c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1158,   11,   14,   17],\n",
       "       [  20, 1171,    6,    3],\n",
       "       [  21,    8, 1166,    5],\n",
       "       [   6,    4,    1, 1189]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a4ce4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix:\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c33aa6",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "* **A beautiful exercise is given...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
