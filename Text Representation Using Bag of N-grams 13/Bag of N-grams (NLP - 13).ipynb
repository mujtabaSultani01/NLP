{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7382233",
   "metadata": {},
   "source": [
    "## Text Representation Using Bag of N-grams\n",
    "**Bag of n-grams** is a common technique used in NLP for text analysis. It involves breaking down a text into smaller pieces called n-grams, which are contiguous sequences of n words. For example, if we have the sentence \"The quick brown fox jumps over the lazy dog,\" and we set n=2, we can create bigrams such as \"the quick,\" \"quick brown,\" \"brown fox,\" etc.\n",
    "\n",
    "The bag of n-grams model then counts the frequency of each n-gram in the text and creates a vector representation of the text based on these counts. This vector can be used for various NLP tasks such as sentiment analysis, topic modeling, and text classification.\n",
    "\n",
    "The term \"bag\" refers to the fact that the order of the n-grams is not considered in this model, only their frequency. This makes it a simple yet effective method for analyzing text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878f196",
   "metadata": {},
   "source": [
    "* **Bag Of Words** approach works fine but if think here we're missing an important point which is, in a language the order of word is important. In Bag of Words model we're just counting individual word but we're not capturing the relationship between the words. If we change the order of words in a sentence, the meaning of sentence will change completely. See the following image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b18d7a",
   "metadata": {},
   "source": [
    "<img src = \"img.png\" width = \"700px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ed010",
   "metadata": {},
   "source": [
    "* So if there is a way to capture the order of the words in a sentence, that would be very useful. So in **Bag of n-grams approach** instead of capturing a single word, we capture pair of words which is called **Bi-gram.** In **Tri-gram** we have a moving window where we capture three words.\n",
    "* The generic term for representing the words is **n-grams.** So we can have 4-grams, 5-grams and so on.\n",
    "* So now in n-gram representation we see some scense, it give almost proper meaning. See the bellow image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab9e3ce",
   "metadata": {},
   "source": [
    "<img src = \"img1.png\" width = \"700px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc49c2",
   "metadata": {},
   "source": [
    "* Generally the **BOW** is a special case of **Bag of n-grams** where the value of n is 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d459e288",
   "metadata": {},
   "source": [
    "<img src = \"img2.png\" width = \"700px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fc43e",
   "metadata": {},
   "source": [
    "* Let's look at some other examples. Here we have three documents. In NLP by documents means a text, a paragraph, a news article and so on. \n",
    "* If you want to build a Bag of Words model, the general approach is, you do some preprocessing, you remove stop words and you do lemmatization and then you will get clean or post processed text. & Then you build a Bag of word model or countVectorizer model. After that you just count the number of words for each document which is called **Bag of Words** or **1-gram.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ba46b",
   "metadata": {},
   "source": [
    "<img src = \"img3.png\" width = \"700px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4855bd",
   "metadata": {},
   "source": [
    "* If we create Bi-grams, it will look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0473d6e",
   "metadata": {},
   "source": [
    "<img src = \"img4.png\" width = \"700px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13149e4e",
   "metadata": {},
   "source": [
    "* So then the generated vectors can be used to train a ML model.\n",
    "* One approach that people use is, they use **1-gram** and **2-gram** combinely, because then you will have a vector which represent the whole sentence in more meaningful way. Here we can have meaningful similarity between two or n documents. So by using 1-gram and bi-gram you can create more meaningful representation of your text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a2f79",
   "metadata": {},
   "source": [
    "<img src = \"img5.png\" width = \"700px\" height = \"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcf9b3",
   "metadata": {},
   "source": [
    "**Limitation of Bag of n-grams model**\n",
    "1. As n increased, dimensionality, sparsity increas.\n",
    "2. Doesn't address out of vocabulary (OOV) problem. While training a model, you train on a certain dataset but when you do prediction, you get totally new words and it's now hard to represent those new words in a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416323cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 5, 'hathodawala': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer()                               # Object of the CountVectorizer\n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])    # Single sentence to be fitted.\n",
    "v.vocabulary_                                       # Will create a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4cdfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor hathodawala': 4,\n",
       " 'hathodawala is': 1,\n",
       " 'is looking': 2,\n",
       " 'looking for': 3,\n",
       " 'for job': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So this is again BOW, if you check the documentation of sklearn library, by default it's 1-gram.\n",
    "# So if we supply 'n-grams' parameter, it will create a pair of words which is bi-grams.\n",
    "\n",
    "v = CountVectorizer(ngram_range = (2,2))            # Will generate 2-grams                                        \n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])    \n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851033d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 9,\n",
       " 'hathodawala': 2,\n",
       " 'is': 4,\n",
       " 'looking': 7,\n",
       " 'for': 0,\n",
       " 'job': 6,\n",
       " 'thor hathodawala': 10,\n",
       " 'hathodawala is': 3,\n",
       " 'is looking': 5,\n",
       " 'looking for': 8,\n",
       " 'for job': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we supply (1,2), it will generate both 1-grams and 2-grams.\n",
    "v = CountVectorizer(ngram_range = (1,2))                              \n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])    \n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781369d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 12,\n",
       " 'hathodawala': 2,\n",
       " 'is': 5,\n",
       " 'looking': 9,\n",
       " 'for': 0,\n",
       " 'job': 8,\n",
       " 'thor hathodawala': 13,\n",
       " 'hathodawala is': 3,\n",
       " 'is looking': 6,\n",
       " 'looking for': 10,\n",
       " 'for job': 1,\n",
       " 'thor hathodawala is': 14,\n",
       " 'hathodawala is looking': 4,\n",
       " 'is looking for': 7,\n",
       " 'looking for job': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we supply (1,3), it will generate 1-grams, 2-grams and 3-grams:\n",
    "v = CountVectorizer(ngram_range = (1,3))                              \n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])    \n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0279749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's have a corpus of three sentences (3 documents).\n",
    "# Corpus is a collection of documents or list of strings.\n",
    "corpus = [                        \n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb21958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For corpus we first write a preprocessing function to remove stop words, do lemmatization and so on, and then we'll apply \n",
    "# Bi-gram CountVectorizer to see how the vector space model look like? (how it convert text into a vector?)\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:    # Will ignore stop words and punctuation marks.\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)   # Lemm_ give us the base word.\n",
    "    \n",
    "    return \" \".join(filtered_tokens)           # Will convert list into a string and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f7e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thor eat pizza'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we pass a single sentence to the function:\n",
    "preprocess(\"Thor ate pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6841f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loki eat pizza'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we try another sentence:\n",
    "preprocess(\"Loki is eating pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a11423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thor eat pizza', 'Loki tall', 'Loki eat pizza']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we run a for loop on our original corpus to preprocess all the documents (sentences).\n",
    "# Here the python list comprehension is used.\n",
    "\n",
    "corpus_processed = [\n",
    "    preprocess(text) for text in corpus\n",
    "]\n",
    "corpus_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3101517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 7,\n",
       " 'eat': 0,\n",
       " 'pizza': 5,\n",
       " 'thor eat': 8,\n",
       " 'eat pizza': 1,\n",
       " 'loki': 2,\n",
       " 'tall': 6,\n",
       " 'loki tall': 4,\n",
       " 'loki eat': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have processed text, we're going to use CountVectorizer to generate both 1-grams and 2-grams (1,2) vocabulary.\n",
    "v = CountVectorizer(ngram_range=(1,2))\n",
    "v.fit(corpus_processed)                     # fit() will create that vocabulary, we just supply the preprocessed text.\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27fbb624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now once the vocabulary is prepared, we can take a new sentence and we can do text to vector conversion on it as ML need \n",
    "# a numbers not text.\n",
    "# Means we convert the new sentence to vector using Bag of n-grams model.\n",
    "\n",
    "# v.transform([\"Thor eat pizza\"])            # will give you a matrix.\n",
    "v.transform([\"Thor eat pizza\"]).toarray()    # will give you an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "094fcbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll try one more sentence:\n",
    "v.transform([\"Hulk eat pizza\"]).toarray()   # Hulk wasn't in our vocabulary, so we'll face OOV problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a6be3",
   "metadata": {},
   "source": [
    "* According to previous created vocabulay it will create vectors from the new sentence, here we see the word 'Hulk' wasn't in our vocabulary so it will be skipped (OOV problem).\n",
    "* See the bellow image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf5c39",
   "metadata": {},
   "source": [
    "<img src = \"thor_hulk.jpg\" width = \"700px\" height = \"400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bdb129",
   "metadata": {},
   "source": [
    "**News Category Classification Problem**\n",
    "\n",
    "Okay now that we know basics of BAG of n grams vectorizer 😎 It is the time to work on a real problem. Here we want to do a news category classification. We will use bag of n-grams and train a machine learning model that can categorize any news into one of the following categories,\n",
    "\n",
    "    1. BUSINESS\n",
    "    2. SPORTS\n",
    "    3. CRIME\n",
    "    4. SCIENCE\n",
    "    \n",
    "\n",
    "**Dataset**\n",
    "\n",
    "Dataset Credits: https://www.kaggle.com/code/hengzheng/news-category-classifier-val-acc-0-65\n",
    "\n",
    "* This data consists of two columns:\n",
    "   1. Text \n",
    "   2. Category\n",
    "   \n",
    "   \n",
    "* Text is a news article\n",
    "* Category can be one of these 4:\n",
    "   1. BUSINESS\n",
    "   2. SPORTS \n",
    "   3. CRIME\n",
    "   4. SCIENCE'\n",
    "  \n",
    "  To keep things simple I trimmed additional categories from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c72596f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching Schrödinger's Cat Die University of C...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Freaky Vortex Opens Up In Flooded Lake</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrepreneurs Today Don't Need a Big Budget to...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These Roads Could Recharge Your Electric Car A...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civilian 'Guard' Fires Gun While 'Protecting' ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Watching Schrödinger's Cat Die University of C...   SCIENCE\n",
       "1     WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
       "2  Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
       "3  These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
       "4  Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So first we import pandas and read the dataset:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('news_dataset.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da5c68fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12695, 2)\n"
     ]
    }
   ],
   "source": [
    "# To see the dataset shape:\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3636a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To quick explore the dataset, we first check the categories:\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5ef90",
   "metadata": {},
   "source": [
    "### Handle class imbalance\n",
    "As you can see above, SCIENCE category has almost 1/3rd data samples compared to BUSINESS and SPORTS categories. I initially trained a model without handling the imbalanced I saw a lower f1-score for SCIENCE category. Hence we need to address this imbalanced.\n",
    "\n",
    "We'll use undersampling technique here.\n",
    "\n",
    "In undersampling, we take a minor class and sample those many samples from other classes, this means we are not utilizing all the data samples for training and in ML world - Not using all the data for training is considered a SIN! 😵 In real life, you are advised to use a technique such as SMOTE so that you can utilize all of your dataset for the training but since this tutorial is more about bag of n-grams then class imbalance itself, I'd go with a simple technique of undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19a49fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS\n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS\n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS\n",
       "502    How to Market Your Business While Traveling th...  BUSINESS\n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we see some imbalance in the dataset, SCIENCE category is much less than BUSINESS and SPORTS. So we need to tackle with\n",
    "# this imbalance. So here we'll use the most simplest technique which is called Under-sampling technique.\n",
    "# So for the SCIENCE category we have 1381 samples, we take randomely 1381 samples from other classes and then we train the \n",
    "# model.\n",
    "# So let's create 1381 samples for BUSINESS class:\n",
    "\n",
    "min_samples = 1381 # we have these many SCIENCE articles and SCIENCE is our minority class.\n",
    "\n",
    "df_business = df[df.category==\"BUSINESS\"].sample(min_samples, random_state=2022)\n",
    "df_business.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f26e1f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>So, Chris Christie Might End Up Replacing Mike...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>'DWTS' Entrant Ryan Lochte Says He Made 'A Ver...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>Cowboys' Decal Proves Roger Goodell Is A Joke ...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>Real or 'Fake,' Violence Against Women is Neve...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>LIVE: Nigeria Takes On Bosnia-Herzegovina For ...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text category\n",
       "11207  So, Chris Christie Might End Up Replacing Mike...   SPORTS\n",
       "1632   'DWTS' Entrant Ryan Lochte Says He Made 'A Ver...   SPORTS\n",
       "5848   Cowboys' Decal Proves Roger Goodell Is A Joke ...   SPORTS\n",
       "5303   Real or 'Fake,' Violence Against Women is Neve...   SPORTS\n",
       "3829   LIVE: Nigeria Takes On Bosnia-Herzegovina For ...   SPORTS"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Sports Class:\n",
    "df_sports = df[df.category==\"SPORTS\"].sample(min_samples, random_state=2022)\n",
    "df_sports.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1a3f077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7630</th>\n",
       "      <td>Passenger Arrested After In-Flight Yoga Sessio...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Man Pleads Guilty In Boy's Fatal Beating Over ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11852</th>\n",
       "      <td>LAPD Hacked Into iPhone Of Slain Wife Of 'Shie...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>U.S. Customs Officers Allegedly Assaulted Cowo...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>TSA Seizes 81 Pounds Of Pot At Airport</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text category\n",
       "7630   Passenger Arrested After In-Flight Yoga Sessio...    CRIME\n",
       "893    Man Pleads Guilty In Boy's Fatal Beating Over ...    CRIME\n",
       "11852  LAPD Hacked Into iPhone Of Slain Wife Of 'Shie...    CRIME\n",
       "12167  U.S. Customs Officers Allegedly Assaulted Cowo...    CRIME\n",
       "2889             TSA Seizes 81 Pounds Of Pot At Airport     CRIME"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For CRIME class: \n",
    "df_crime = df[df.category==\"CRIME\"].sample(min_samples, random_state=2022)\n",
    "df_crime.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f106591e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>It's Time We Take A Look At How Female Astrono...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12292</th>\n",
       "      <td>Scientists Reveal The Secret Key To Charisma I...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>Watch One Of The World's Largest Lakes Shrink ...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>'Falling Fruit' Map Helps Foragers Find Their ...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12505</th>\n",
       "      <td>When Science Fiction Gets Real Many science fi...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text category\n",
       "7210   It's Time We Take A Look At How Female Astrono...  SCIENCE\n",
       "12292  Scientists Reveal The Secret Key To Charisma I...  SCIENCE\n",
       "6249   Watch One Of The World's Largest Lakes Shrink ...  SCIENCE\n",
       "379    'Falling Fruit' Map Helps Foragers Find Their ...  SCIENCE\n",
       "12505  When Science Fiction Gets Real Many science fi...  SCIENCE"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For SCIENCE class we take all the samples. \n",
    "df_science = df[df.category==\"SCIENCE\"].sample(min_samples, random_state=2022)\n",
    "df_science.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2021260",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    1381\n",
       "SPORTS      1381\n",
       "CRIME       1381\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So to join these samples, we use concate function.\n",
    "# axis=0 => join the DataFrames on row-level.\n",
    "\n",
    "df_balanced = pd.concat([df_business,df_sports,df_crime,df_science],axis=0)\n",
    "df_balanced.category.value_counts() # Will shows us the numbers of values for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "212a320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we have to convert the Category column into numbers.\n",
    "# So we create a new column 'category_num' and on exist column 'category' we apply 'map()' function to convert strings \n",
    "# into numbers.\n",
    "\n",
    "# target = {'BUSINESS': 0, 'SPORTS': 1, 'CRIME': 2, 'SCIENCE': 3}\n",
    "\n",
    "df_balanced['category_num'] = df_balanced['category'].map({\n",
    "    'BUSINESS': 0,\n",
    "    'SPORTS': 1, \n",
    "    'CRIME': 2, \n",
    "    'SCIENCE': 3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f941035d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>Who Wanted This Dentist Dead? \"She admitted th...</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>Gunfire Outside Colorado State Capitol Forces ...</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12541</th>\n",
       "      <td>Fan At Dodger Stadium Gets Really Comfortable</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338</th>\n",
       "      <td>5 Ways the IRS Scammers Could Have Stolen All ...</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10056</th>\n",
       "      <td>Principles-Based Regulation and Compliance: A ...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "5045   Who Wanted This Dentist Dead? \"She admitted th...     CRIME   \n",
       "3378   Gunfire Outside Colorado State Capitol Forces ...     CRIME   \n",
       "12541     Fan At Dodger Stadium Gets Really Comfortable     SPORTS   \n",
       "4338   5 Ways the IRS Scammers Could Have Stolen All ...     CRIME   \n",
       "10056  Principles-Based Regulation and Compliance: A ...  BUSINESS   \n",
       "\n",
       "       category_num  \n",
       "5045              2  \n",
       "3378              2  \n",
       "12541             1  \n",
       "4338              2  \n",
       "10056             0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the new column and assigned category numbers:\n",
    "df_balanced.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37630808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our dataset is ready and we call train_test_split method to split the dataset:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.text, \n",
    "    df_balanced.category_num, \n",
    "    test_size=0.2,                       # 20% samples will go to test dataset\n",
    "    random_state=2022,                   # If the notebook is run multiple times the valus will not change.\n",
    "    stratify=df_balanced.category_num    # It will create equal number of samples from all the classes in train and test.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47115aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4419,)\n"
     ]
    }
   ],
   "source": [
    "# To check the X_train shape:\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0c3a609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7589     Ovulating Women Prefer Images of Penetration O...\n",
       "10442    Scientists Discover Spooky Influence On Baby N...\n",
       "8792     Olympic Race Walker Steps Up To Propose To His...\n",
       "1733     Beloved Bipedal Bear Named Pedals Believed Kil...\n",
       "2526     Elizabeth Smart Gave Birth To Baby Girl, Fathe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see five of the X_train samples\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "454a26ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1105\n",
       "2    1105\n",
       "0    1105\n",
       "1    1104\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the values for y_train from each class:\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99d3b0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    277\n",
       "0    276\n",
       "3    276\n",
       "2    276\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check it for y_test also:\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "745e6a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81       276\n",
      "           1       0.93      0.80      0.86       277\n",
      "           2       0.83      0.90      0.86       276\n",
      "           3       0.90      0.80      0.85       276\n",
      "\n",
      "    accuracy                           0.84      1105\n",
      "   macro avg       0.85      0.84      0.84      1105\n",
      "weighted avg       0.85      0.84      0.84      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next we create a Bag of Words model. \n",
    "\n",
    "# Necessary libraries...\n",
    "from sklearn.naive_bayes import MultinomialNB       # We use 'Naive Bayes' for classification purpose.\n",
    "from sklearn.pipeline import Pipeline               # Pipeline takes list of arguments and we define CountVectorizer and\n",
    "                                                    # classification model.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer()),        # We use simple CountVectorizer => 1-grams. \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)             # Train the model\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea15b1d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       276\n",
      "           1       0.95      0.74      0.83       277\n",
      "           2       0.82      0.88      0.85       276\n",
      "           3       0.92      0.78      0.84       276\n",
      "\n",
      "    accuracy                           0.82      1105\n",
      "   macro avg       0.85      0.82      0.83      1105\n",
      "weighted avg       0.85      0.82      0.83      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now here we use 1-grams and 2-grams both and see the performance.\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 2))),    # Using the ngram_range parameter.    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)            \n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "945abaaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77       276\n",
      "           1       0.96      0.73      0.83       277\n",
      "           2       0.83      0.87      0.85       276\n",
      "           3       0.93      0.76      0.83       276\n",
      "\n",
      "    accuracy                           0.82      1105\n",
      "   macro avg       0.84      0.82      0.82      1105\n",
      "weighted avg       0.84      0.82      0.82      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try 3-grams.\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 3))),    # Using the ngram_range parameter.    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)            \n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f810f",
   "metadata": {},
   "source": [
    "* So we see the performances of 2-grams and 3-grams are little lower than Bag of Words (1-grams), but it's ok, based on a given dataset will try to find the best accuracy and we'll try each of the n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ebf1862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716     African Nation Slaps Exxon With Fine Nearly 7 ...\n",
       "608      These Cringe-Worthy Stories Show It Can Be Har...\n",
       "11172    LISTEN: The Accidental Discovery That Proved T...\n",
       "1346     Build Loyalty -- The Cost -- $00.00 Remember y...\n",
       "1356     Man Killed By Michigan Police Wasn't Targeting...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to make some prediction, so our first five articles are:\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f04c49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716     0\n",
       "608      3\n",
       "11172    3\n",
       "1346     0\n",
       "1356     2\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we look at five first categories:\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27fc7d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And our prediction through the model is:\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7c4c1",
   "metadata": {},
   "source": [
    "* We see 4 out of five is predicted properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791482e0",
   "metadata": {},
   "source": [
    "### Use text pre-processing to remove stop words, punctuations and apply lemmatization\n",
    "You may wonder, we have not done any text-processing yet to remove stop words, punctuations, apply lemmatization etc. Well we wanted to train the model without any preprocessing first and check the performance. Now we will re-do same thing but with preprocessing of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8c8bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So here we create a new column 'preprocessed_text' for pre-processed text.\n",
    "df_balanced['preprocessed_txt'] = df_balanced['text'].apply(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b471b8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>GCC Business Leaders remain Confident Face Reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Honest Review employee wake morning love impor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Mike McDerment ceo FreshBooks Talks give build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>market business travel World recently amazing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Leverage intuition decision making feel safe r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_num                                   preprocessed_txt  \n",
       "11967             0  GCC Business Leaders remain Confident Face Reg...  \n",
       "2912              0  Honest Review employee wake morning love impor...  \n",
       "3408              0  Mike McDerment ceo FreshBooks Talks give build...  \n",
       "502               0  market business travel World recently amazing ...  \n",
       "5279              0  Leverage intuition decision making feel safe r...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see some reviews whether preprocessed or not:\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32cc4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll train the same model but with one differece, instead of 'text' column we use 'preprocessed_txt' column:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.preprocessed_txt, \n",
    "    df_balanced.category_num, \n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=df_balanced.category_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62d51b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1105\n",
       "2    1105\n",
       "0    1105\n",
       "1    1104\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again if we see the number of y_train from each class:\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5c9c189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    277\n",
       "0    276\n",
       "3    276\n",
       "2    276\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar for y_test:\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e64fda75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       276\n",
      "           1       0.92      0.82      0.87       277\n",
      "           2       0.83      0.92      0.87       276\n",
      "           3       0.90      0.81      0.85       276\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.86      0.86      0.86      1105\n",
      "weighted avg       0.86      0.86      0.86      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So we train the model with same 2-grams vocabulary.\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range = (1, 2))),      \n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cb87b",
   "metadata": {},
   "source": [
    "* If you compare above classification report for (1,2) gram with the one from unprocessed text, you will find some improvement in the model that uses preprocessed cleaned up text. Hence we can conclude that for this particular problem using preprocessing (removing stop words, lemmatization) is improving the performance of the model.\n",
    "* In this problem removing stop words, lemmatization ... have a scense but if we have other cases like sentiment analysis, we'll check both the cases whther removing stop words ... has scense or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "665a4dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[243,   8,  17,   8],\n",
       "       [ 10, 228,  29,  10],\n",
       "       [ 15,   2, 253,   6],\n",
       "       [ 36,   9,   7, 224]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To have confusion matrix:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c63c5a9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confution matrix in a better way:\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45529f",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "* **A beautiful exercise is given...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
